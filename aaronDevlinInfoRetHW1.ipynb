{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. There are 237224 word tokens in the database.\n",
      "2. From these total tokens, there are 10686 unique tokens.\n",
      "3. 4614 tokens were said only once.\n",
      "4. Statistics for the 30 most frequent words are shown below.\n",
      "          TF    N   DF       IDF      TFxIDF      Prob\n",
      "i       9867  404  401  0.007453   73.543198  0.041594\n",
      "and     7958  404  401  0.007453   59.314560  0.033546\n",
      "the     6490  404  398  0.014963   97.109044  0.027358\n",
      "to      6253  404  403  0.002478   15.496910  0.026359\n",
      "a       5315  404  399  0.012453   66.190146  0.022405\n",
      "you     5111  404  395  0.022529  115.146297  0.021545\n",
      "that    4112  404  386  0.045578  187.414715  0.017334\n",
      "it      3813  404  387  0.042990  163.921575  0.016073\n",
      "of      3626  404  389  0.037836  137.191648  0.015285\n",
      "so      3142  404  389  0.037836  118.879249  0.013245\n",
      "like    3052  404  363  0.107012  326.600757  0.012865\n",
      "is      2510  404  381  0.058616  147.124912  0.010581\n",
      "my      2490  404  371  0.085213  212.179910  0.010496\n",
      "in      2456  404  381  0.058616  143.959675  0.010353\n",
      "im      2400  404  372  0.082521  198.050457  0.010117\n",
      "um      2377  404  294  0.317835  755.494058  0.010020\n",
      "know    2187  404  356  0.126484  276.620830  0.009219\n",
      "this    2158  404  379  0.063879  137.850176  0.009097\n",
      "its     2134  404  361  0.112537  240.153786  0.008996\n",
      "but     2032  404  361  0.112537  228.675021  0.008566\n",
      "just    1974  404  351  0.140629  277.600964  0.008321\n",
      "was     1909  404  307  0.274567  524.148652  0.008047\n",
      "for     1791  404  351  0.140629  251.865920  0.007550\n",
      "on      1767  404  351  0.140629  248.490832  0.007449\n",
      "have    1729  404  365  0.101518  175.523800  0.007288\n",
      "me      1456  404  331  0.199297  290.175708  0.006138\n",
      "be      1432  404  329  0.205357  294.071406  0.006036\n",
      "really  1426  404  308  0.271315  386.895325  0.006011\n",
      "not     1400  404  337  0.181332  253.864727  0.005902\n",
      "dont    1362  404  331  0.199297  271.441837  0.005741\n",
      "5. There are 587.1881188118812 tokens per document on average.\n"
     ]
    }
   ],
   "source": [
    "import os, string, numpy, pandas, nltk\n",
    "\n",
    "docnames = os.listdir('transcripts')\n",
    "doccount = len(docnames) #404 vlogs\n",
    "\n",
    "dtdf = pandas.DataFrame(index = docnames, columns = ['#Tokens', 'Tokens']) #DOCUMENT DF: rows = doc names, cols = num tokens & string of all tokens\n",
    "\n",
    "alltxt =\"\"\n",
    "for vlogi in (docnames):\n",
    "    vltxt =  open('transcripts/' + vlogi, encoding='utf-8-sig').read()\n",
    "    vltxt = vltxt.lower().replace('\\ufeff', '')\n",
    "    alltxt += vltxt\n",
    "    doctokens = nltk.word_tokenize(vltxt.translate(str.maketrans('','',string.punctuation)))\n",
    "    dtdf.loc[vlogi] = pandas.Series({'#Tokens':len(doctokens), 'Tokens':doctokens}) # fill data\n",
    "\n",
    "alltokens = nltk.word_tokenize(alltxt.translate(str.maketrans('','',string.punctuation))) #list of all tokens in the db including repeats\n",
    "uniqs = set(alltokens)\n",
    "\n",
    "alltkct = {} #for each token, what is the count for that token in the entire db\n",
    "for tkn in alltokens:\n",
    "    try: alltkct[tkn] += 1\n",
    "    except KeyError: alltkct[tkn] = 1\n",
    "\n",
    "onces = 0\n",
    "for tkn in alltkct:\n",
    "    if(alltkct[tkn] == 1):\n",
    "        onces += 1\n",
    "        \n",
    "tstatdf = pandas.DataFrame.from_dict(alltkct, orient='index').rename(columns={0:'TF'}) #TOKEN DF: rows = tokens, cols = statistics\n",
    "tstatdf.sort_values(['TF'], ascending= False, inplace = True)\n",
    "tstatdf = tstatdf.iloc[:30]\n",
    "\n",
    "tstatdf['N'] = doccount\n",
    "tstatdf['DF'] = 0\n",
    "\n",
    "for tkn in tstatdf.index.values:\n",
    "    for tokens in dtdf['Tokens']:\n",
    "        if tkn in tokens:\n",
    "            tstatdf.loc[tkn,'DF'] += 1\n",
    "\n",
    "tstatdf['IDF'] = numpy.log(tstatdf['N'].divide(tstatdf['DF']))\n",
    "tstatdf['TFxIDF'] = tstatdf['TF'] * tstatdf['IDF']\n",
    "tstatdf['Prob'] = tstatdf['TF'].divide(len(alltokens))\n",
    "\n",
    "print('1. There are', len(alltokens), 'word tokens in the database.')\n",
    "print('2. From these total tokens, there are', len(uniqs), 'unique tokens.')\n",
    "print('3.', onces, 'tokens were said only once.')\n",
    "print('4. Statistics for the 30 most frequent words are shown below.')\n",
    "print(tstatdf)\n",
    "print('5. There are', len(alltokens)/404, 'tokens per document on average.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
